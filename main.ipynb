{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\57300\\Documents\\UdeA\\2023-2\\Lab-PDS\\ProyectoFourier\\venv\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read\n",
    "from  IPython.display import Audio\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.io.wavfile import write\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=6):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'acordes.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_audio\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39macordes.wav\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m fs,x\u001b[39m=\u001b[39mread(file_audio)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(x)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mla frecuencia de muestreo es \u001b[39m\u001b[39m{\u001b[39;00mfs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\57300\\Documents\\UdeA\\2023-2\\Lab-PDS\\ProyectoFourier\\venv\\lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    649\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[39m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'acordes.wav'"
     ]
    }
   ],
   "source": [
    "file_audio=('acordes.wav')\n",
    "fs,x=read(file_audio)\n",
    "print(x)\n",
    "print(f'la frecuencia de muestreo es {fs}')\n",
    "# x_seconds=x[:2*fs]\n",
    "time=np.arange(0,len(x)/fs,1.0/fs)\n",
    "if len(x) > len(time):\n",
    "    x = x[:len(time)]\n",
    "elif len(x) < len(time):\n",
    "    time = time[:len(x)]\n",
    "\n",
    "# Graficar la forma de onda de audio\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.plot(time, x)\n",
    "plt.title(\"Forma de Onda de Audio\")\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#Reproducción de la señal de audio. \n",
    "\n",
    "audio = AudioSegment.from_file(\"acordes.wav\")\n",
    "\n",
    "#Especifica la ruta del archivo de audio\n",
    "audio_file = 'acordes.wav'\n",
    "#Crea un widget de audio y reprodúcelo\n",
    "audio = Audio(filename=audio_file, autoplay=True)\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 1  # Duración de cada segmento en segundos\n",
    "samples_per_segment = int(segment_duration * fs)\n",
    "num_segments = len(x) // samples_per_segment\n",
    "\n",
    "# Procesar cada segmento\n",
    "for segment_idx in range(num_segments):\n",
    "    start = segment_idx * samples_per_segment\n",
    "    end = start + samples_per_segment\n",
    "    segment = x[start:end]\n",
    "\n",
    "    # Aquí puedes realizar el análisis de acordes para cada segmento\n",
    "    # Puedes utilizar la librería librosa o cualquier otra que prefieras.\n",
    "\n",
    "    # Graficar el segmento (puedes quitar esto si no es necesario)\n",
    "    time = np.arange(start / fs, end / fs, 1.0 / fs)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(time, segment)\n",
    "    plt.title(f\"Segmento {segment_idx + 1}\")\n",
    "    plt.xlabel(\"Tiempo (s)\")\n",
    "    plt.ylabel(\"Amplitud\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Reproducir el audio completo\n",
    "audio = AudioSegment.from_file(\"acordes.wav\")\n",
    "audio_file = 'acordes.wav'\n",
    "audio = AudioSegment.from_file(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dft(segment, fs):\n",
    "    N = len(segment)\n",
    "    T = 1.0 / fs\n",
    "    # Calcular la DFT\n",
    "    dft = np.fft.fft(segment)\n",
    "    # Calcular las frecuencias correspondientes\n",
    "    freqs = np.fft.fftfreq(N, T)\n",
    "    return freqs, dft\n",
    "\n",
    "\n",
    "def detect_chords(freqs, dft):\n",
    "    threshold = 0.1  # Umbral para considerar un pico\n",
    "    peaks = np.where(abs(dft) > threshold)[0]  # Obtener índices de los picos\n",
    "    detected_chords = []\n",
    "    \n",
    "    for peak in peaks:\n",
    "        # Aquí puedes mapear las frecuencias a notas musicales y acordes\n",
    "        freq = freqs[peak]\n",
    "        note = map_freq_to_note(freq)  # Usamos la función map_freq_to_note\n",
    "        detected_chords.append(note)\n",
    "    \n",
    "    return detected_chords\n",
    "\n",
    "\n",
    "def map_freq_to_note(freq, tuning_freq=440.0):\n",
    "    # Frecuencia de referencia (A4 en afinación estándar)\n",
    "    A4 = tuning_freq\n",
    "    \n",
    "    # Factor de conversión para semitonos (12 semitonos por octava)\n",
    "    semitone_ratio = 2 ** (1 / 12)\n",
    "    \n",
    "    # Calcular la distancia en semitonos desde A4\n",
    "    semitone_distance = 12 * np.log2(freq / A4)\n",
    "    \n",
    "    # Notas musicales (0 = A4, 12 = A5, -12 = A3, etc.)\n",
    "    note_names = [\"A\", \"A#\", \"B\", \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\"]\n",
    "    \n",
    "    # Determinar la nota más cercana\n",
    "    nearest_note = note_names[int(round(semitone_distance)) % 12]\n",
    "    \n",
    "    return nearest_note\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def map_freq_to_note(freq, tuning_freq=440.0):\n",
    "    A4 = tuning_freq\n",
    "    semitone_ratio = 2 ** (1 / 12)\n",
    "    \n",
    "    if np.isfinite(freq):  # Verificar si la frecuencia es finita\n",
    "        semitone_distance = 12 * np.log2(freq / A4)\n",
    "        note_names = [\"A\", \"A#\", \"B\", \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\"]\n",
    "        nearest_note = note_names[int(round(semitone_distance)) % 12]\n",
    "        return nearest_note\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_chords(freqs, dft):\n",
    "    threshold = 0.1  # Umbral para considerar un pico\n",
    "    peaks = np.where(abs(dft) > threshold)[0]  # Obtener índices de los picos\n",
    "    detected_chords = []\n",
    "\n",
    "    for peak in peaks:\n",
    "        freq = freqs[peak]\n",
    "        note = map_freq_to_note(freq)  # Mapear frecuencia a nota\n",
    "        detected_chords.append(note)\n",
    "\n",
    "    return detected_chords\n",
    "\n",
    "# Cargar el archivo de audio\n",
    "file_audio = 'acordes.wav'\n",
    "fs, x = wavfile.read(file_audio)\n",
    "\n",
    "# Graficar la forma de onda de audio\n",
    "time = np.arange(0, len(x) / fs, 1.0 / fs)\n",
    "if len(x) > len(time):\n",
    "    x = x[:len(time)]\n",
    "elif len(x) < len(time):\n",
    "    time = time[:len(x)]\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.plot(time, x)\n",
    "plt.title(\"Forma de Onda de Audio\")\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Dividir el audio en segmentos\n",
    "segment_size = 1024\n",
    "num_segments = len(x) // segment_size\n",
    "chords_detected = []\n",
    "\n",
    "for i in range(num_segments):\n",
    "    start = i * segment_size\n",
    "    end = start + segment_size\n",
    "    segment = x[start:end]\n",
    "    \n",
    "    dft = np.abs(np.fft.fft(segment))\n",
    "    freqs = np.fft.fftfreq(len(segment), 1 / fs)\n",
    "    \n",
    "    chords = detect_chords(freqs, dft)\n",
    "    chords_detected.extend(chords)\n",
    "\n",
    "print(\"Notas detectadas en cada segmento:\", chords_detected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESO DE FILTRADO DE LA SEÑAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cutoff_frequency =5000  # Ajusta la frecuencia de corte según tus necesidades\n",
    "order = 4  # Orden del filtro, ajusta según tus necesidades\n",
    "\n",
    "# Aplicar el filtro a la señal del pulso cardíaco\n",
    "filtered_signal = butter_lowpass_filter(x, cutoff_frequency, fs, order)\n",
    "\n",
    "# Crear un vector de tiempo para la señal filtrada\n",
    "time_filtered = np.arange(0, len(filtered_signal) / fs, 1.0 / fs)\n",
    "\n",
    "if len(filtered_signal) > len(time_filtered):\n",
    "    filtered_signal = filtered_signal[:len(time_filtered)]\n",
    "elif len(filtered_signal) < len(time_filtered):\n",
    "    time_filtered = time_filtered[:len(filtered_signal)]\n",
    "\n",
    "# Graficar la forma de onda de la señal del pulso cardíaco filtrada\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.xlim(0,5)\n",
    "plt.plot(time_filtered, filtered_signal)\n",
    "plt.title(\"Forma de Onda del Pulso Cardíaco Filtrada\")\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "write(\"filtered_audio.wav\", fs, np.int16(filtered_signal))\n",
    "\n",
    "audio = AudioSegment.from_file(\"filtered_audio.wav\")\n",
    "\n",
    "#Especifica la ruta del archivo de audio\n",
    "audio_file = 'filtered_audio.wav'\n",
    "#Crea un widget de audio y reprodúcelo\n",
    "audio = Audio(filename=audio_file, autoplay=True)\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latidos = []\n",
    "\n",
    "# Segmentar la señal en latidos\n",
    "for i in range(len(peaks) - 1):\n",
    "    latido = xf[peaks[i]:peaks[i + 1]]\n",
    "    latidos.append(latido)\n",
    "\n",
    "# Calcular la DFT de cada latido\n",
    "espectros_de_frecuencia = []\n",
    "for latido in latidos:\n",
    "    N = len(latido)\n",
    "    espectro = np.abs(np.fft.fft(latido))\n",
    "    frecuencias = np.fft.fftfreq(N, 1 / fs)\n",
    "    espectros_de_frecuencia.append((frecuencias, espectro))\n",
    "\n",
    "# Promediar los espectros de frecuencia\n",
    "# Encuentra la longitud máxima de los espectros de frecuencia\n",
    "max_length = max(len(espectro) for _, espectro in espectros_de_frecuencia)\n",
    "\n",
    "# Rellena los espectros de frecuencia con ceros para que tengan la misma longitud\n",
    "espectros_de_frecuencia = [(frecuencias, np.pad(espectro, (0, max_length - len(espectro)))) for _, espectro in espectros_de_frecuencia]\n",
    "\n",
    "# Calcula el espectro de frecuencia promedio\n",
    "espectro_promedio = np.mean([espectro for _, espectro in espectros_de_frecuencia], axis=0)\n",
    "# Visualizar el espectro promedio\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(espectros_de_frecuencia[0][0], espectro_promedio)  # Accede a las frecuencias desde espectros_de_frecuencia[0][0]\n",
    "plt.title(\"Espectro de Frecuencia Promedio\")\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Cargar el archivo de audio\n",
    "audio_file = 'tu_archivo_de_audio.wav'\n",
    "fs, x = wavfile.read(audio_file)\n",
    "\n",
    "# Diseñar los filtros para las frecuencias DTMF\n",
    "f1 = [697, 770, 852, 941]\n",
    "f2 = [1209, 1336, 1477]\n",
    "dtmf = f1 + f2\n",
    "\n",
    "# Inicializar matrices para almacenar las amplitudes de las frecuencias DTMF\n",
    "amplitudes_f1 = np.zeros(len(dtmf))\n",
    "amplitudes_f2 = np.zeros(len(dtmf))\n",
    "\n",
    "# Calcular la DFT de la señal de audio\n",
    "X = np.fft.fft(x)\n",
    "N = len(x)\n",
    "frequencies = np.arange(N) * (fs / N)\n",
    "\n",
    "# Calcular las amplitudes de las frecuencias DTMF\n",
    "for i in range(len(dtmf)):\n",
    "    f1_freq = dtmf[i]\n",
    "    f2_freq = dtmf[i + len(f1)]\n",
    "\n",
    "    index_f1 = np.argmin(np.abs(frequencies - f1_freq))\n",
    "    index_f2 = np.argmin(np.abs(frequencies - f2_freq))\n",
    "\n",
    "    amplitudes_f1[i] = np.abs(X[index_f1])\n",
    "    amplitudes_f2[i] = np.abs(X[index_f2])\n",
    "\n",
    "# Encontrar las frecuencias DTMF dominantes\n",
    "threshold = 0.2  # Ajusta este valor según tus necesidades\n",
    "max_amplitude_f1 = max(amplitudes_f1)\n",
    "max_amplitude_f2 = max(amplitudes_f2)\n",
    "dominant_f1 = [i for i, amplitude in enumerate(amplitudes_f1) if amplitude > threshold * max_amplitude_f1]\n",
    "dominant_f2 = [i for i, amplitude in enumerate(amplitudes_f2) if amplitude > threshold * max_amplitude_f2]\n",
    "\n",
    "# Mapear las frecuencias dominantes a dígitos\n",
    "dtmf_symbols = [['1', '2', '3', 'A'], ['4', '5', '6', 'B'], ['7', '8', '9', 'C'], ['*', '0', '#', 'D']]\n",
    "\n",
    "if dominant_f1 and dominant_f2:\n",
    "    detected_digit = dtmf_symbols[dominant_f2[0]][dominant_f1[0]]\n",
    "    print(f'El dígito detectado es: {detected_digit}')\n",
    "else:\n",
    "    print('No se detectó ninguna señal DTMF.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDSp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
